{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2d = torch.randn(20, 100, 35, 45)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7684e-07)\n"
     ]
    }
   ],
   "source": [
    "# BatchNorm2d: affine=False, track_running_stats=False\n",
    "m_bn2d_1 = nn.BatchNorm2d(100, affine=False,track_running_stats=False,eps=0)\n",
    "out1_bn2d_1 = m_bn2d_1(inp_2d)\n",
    "out2_bn2d_1 = (inp_2d-inp_2d.mean(dim=(0,2,3),keepdim=True))/(inp_2d.std(dim=(0,2,3),keepdim=True,unbiased=False))\n",
    "print((out1_bn2d_1-out2_bn2d_1).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor(1.9073e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# BatchNorm2d: affine=True, track_running_stats=False\n",
    "m_bn2d_2 = nn.BatchNorm2d(100, affine=True,track_running_stats=False,eps=0)\n",
    "m_bn2d_2.weight.data.normal_()\n",
    "m_bn2d_2.bias.data.normal_()\n",
    "out1_bn2d_2 = m_bn2d_2(inp_2d)\n",
    "out2_bn2d_2 = (inp_2d-inp_2d.mean(dim=(0,2,3),keepdim=True))/(inp_2d.std(dim=(0,2,3),keepdim=True,unbiased=False))\n",
    "out2_bn2d_2=(out2_bn2d_2*m_bn2d_2.weight[None,:,None,None])+m_bn2d_2.bias[None,:,None,None]\n",
    "print((out1_bn2d_2-out2_bn2d_2).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9073e-06, grad_fn=<MaxBackward1>)\n",
      "tensor(5.7220e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# BatchNorm2d: affine=True, track_running_stats=True\n",
    "m_bn2d_3 = nn.BatchNorm2d(100, affine=True,track_running_stats=True)\n",
    "m_bn2d_3.weight.data.normal_()\n",
    "m_bn2d_3.bias.data.normal_()\n",
    "m_bn2d_3.train()\n",
    "out1_bn2d_3 = m_bn2d_3(inp_2d)\n",
    "out2_bn2d_3 = (inp_2d-inp_2d.mean(dim=(0,2,3),keepdim=True))/  \\\n",
    "np.sqrt(inp_2d.var(dim=(0,2,3),keepdim=True,unbiased=False)+m_bn2d_3.eps)\n",
    "\n",
    "out2_bn2d_3=(out2_bn2d_3*m_bn2d_3.weight[None,:,None,None])+m_bn2d_3.bias[None,:,None,None]\n",
    "print((out1_bn2d_3-out2_bn2d_3).abs().max())\n",
    "\n",
    "m_bn2d_3.eval()\n",
    "out1_bn2d_3 = m_bn2d_3(inp_2d)\n",
    "out2_bn2d_3=(inp_2d-m_bn2d_3.running_mean[None,:,None,None])/torch.sqrt(m_bn2d_3.running_var[None,:,None,None]+m_bn2d_3.eps)\n",
    "out2_bn2d_3=(out2_bn2d_3*m_bn2d_3.weight[None,:,None,None])+m_bn2d_3.bias[None,:,None,None]\n",
    "print((out1_bn2d_3-out2_bn2d_3).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.BatchNorm1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1d=torch.randn(20,35,100)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2925,  0.7966, -0.7367, -0.6469,  0.7676,  0.3077, -1.1125, -0.8462,\n",
       "        -2.6437, -0.1936, -0.0811,  0.7204,  1.6462, -1.4753,  0.0702,  0.3489,\n",
       "         0.6849, -1.6422,  0.2395, -0.4500, -0.2770,  1.3101,  2.3897, -1.8086,\n",
       "        -1.2602, -0.9702, -0.7591,  0.5849, -0.5498, -1.4289,  2.0940,  1.8600,\n",
       "        -0.8148, -2.4297,  1.3035])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_bn1d=nn.BatchNorm1d(35)\n",
    "m_bn1d.weight.data.normal_()\n",
    "m_bn1d.bias.data.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5367e-07, grad_fn=<MaxBackward1>)\n",
      "tensor(1.9073e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "m_bn1d.train()\n",
    "out1_bn1d=m_bn1d(inp_1d)\n",
    "out2_bn1d=(inp_1d-inp_1d.mean(dim=(0,2),keepdim=True))/torch.sqrt(inp_1d.var(dim=(0,2),keepdim=True,unbiased=False)+m_bn1d.eps)\n",
    "out2_bn1d=out2_bn1d*m_bn1d.weight[None,:,None]+m_bn1d.bias[None,:,None]\n",
    "print((out1_bn1d-out2_bn1d).abs().max())\n",
    "\n",
    "m_bn1d.eval()\n",
    "out1_bn1d=m_bn1d(inp_1d)\n",
    "out2_bn1d=(inp_1d-m_bn1d.running_mean[None,:,None])/torch.sqrt(m_bn1d.running_var[None,:,None]+m_bn1d.eps)\n",
    "out2_bn1d=out2_bn1d*m_bn1d.weight[None,:,None]+m_bn1d.bias[None,:,None]\n",
    "print((out1_bn1d-out2_bn1d).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InstanceNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.InstanceNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2d = torch.randn(20, 100, 35, 45)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0197, -0.2637, -0.1892,  0.0169,  0.4926, -0.1371, -0.8044,  0.6312,\n",
       "        -0.1256,  1.7203, -1.3780, -1.1240, -0.7845,  0.8835,  0.3241,  0.1730,\n",
       "         0.7913,  0.7250,  0.8551, -1.0900, -0.5454, -1.2181, -1.5272, -0.6476,\n",
       "        -0.4272, -0.6251,  2.6531,  1.2946,  1.6765, -1.4517, -1.5321, -0.8618,\n",
       "        -0.4392, -1.0031,  0.1133, -0.6450, -0.4325,  1.0109,  0.4099,  0.5670,\n",
       "        -0.8679, -1.0621,  0.1606,  0.9934,  0.0745,  0.2096,  1.2718,  0.5572,\n",
       "         1.7677,  0.3772,  0.8835,  0.3090, -0.2385, -0.9725, -0.2218,  0.1654,\n",
       "        -0.2244,  0.0734,  0.6947, -1.0699, -1.3008,  0.0041,  2.8195,  0.1725,\n",
       "        -0.6181,  0.4594, -0.5172,  1.7754, -1.3250,  0.9818,  0.6857, -0.2442,\n",
       "        -0.4482,  0.3124,  0.1274, -1.5520, -1.3876, -0.3538, -0.5420, -2.7162,\n",
       "        -0.2971, -0.9713, -1.7945, -0.7317, -0.4323,  0.3192,  0.7896,  0.6281,\n",
       "         1.6418,  0.0272, -1.5975,  1.8000, -1.2982,  0.1671,  0.8781, -0.3138,\n",
       "        -0.7231, -0.7242,  0.1802, -1.1547])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_in2d=nn.InstanceNorm2d(100,affine=True,track_running_stats=True)\n",
    "m_in2d.weight.data.normal_()\n",
    "m_in2d.bias.data.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9073e-06, grad_fn=<MaxBackward1>)\n",
      "tensor(7.6294e-06)\n"
     ]
    }
   ],
   "source": [
    "running_mean_last=m_in2d.running_mean.clone()\n",
    "out1_in2d=m_in2d(inp_2d)\n",
    "out2_in2d=(inp_2d-inp_2d.mean(dim=(2,3),keepdim=True))/torch.sqrt(inp_2d.var(dim=(2,3),keepdim=True,unbiased=False)+m_in2d.eps)\n",
    "out2_in2d=out2_in2d*m_in2d.weight[None,:,None,None]+m_in2d.bias[None,:,None,None]\n",
    "print((out1_in2d-out2_in2d).abs().max())\n",
    "# The running mean averages across the batch dimension as in the Pytorch C++ code Normalization.cpp\n",
    "print((m_in2d.running_mean-((1-m_in2d.momentum)*running_mean_last+m_in2d.momentum*inp_2d.mean(dim=(0,2,3),keepdim=False))).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.InstanceNorm1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1d = torch.randn(20, 100, 35)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3772,  1.3220, -0.1419, -0.9747,  0.5957, -0.3933, -0.8318, -0.2528,\n",
       "         0.4049,  0.2977,  1.1555,  0.8780,  0.6283, -0.8140,  1.4576,  0.2989,\n",
       "        -0.4481,  0.5360, -1.5799,  0.1240,  0.3458, -0.5718, -0.1517,  0.5443,\n",
       "        -0.4988,  0.3967, -0.3738, -1.1931,  0.7341,  0.2635,  1.8829, -0.2817,\n",
       "        -0.5977, -1.0369,  0.1412,  0.3312,  0.7811, -0.6466,  0.3297, -0.2805,\n",
       "         1.1135,  0.5369, -0.6329,  0.9211,  0.4083,  0.5627,  0.4439,  2.1032,\n",
       "         0.4296, -2.0104,  0.2074, -1.2971, -0.1185,  0.6236, -0.6749,  0.0420,\n",
       "         0.5138, -0.3828, -0.4248, -2.2613, -0.4070, -1.1821, -1.4438,  0.3682,\n",
       "         1.0151, -0.0926, -0.6053,  0.4498,  0.8613, -0.7680, -1.5074, -0.7037,\n",
       "         1.4493,  0.7780, -0.6161,  0.8062,  1.5613, -0.1680,  0.0371,  1.3800,\n",
       "        -1.3432, -1.0245, -0.1183,  0.0307, -0.9204, -0.9425, -2.2076, -0.5570,\n",
       "         0.8127, -0.2700, -0.4865, -0.0836, -1.3501, -0.9473,  0.1009,  1.0256,\n",
       "         0.1608,  0.6199, -0.9670, -0.1869])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_in1d=nn.InstanceNorm1d(100,affine=True,track_running_stats=True)\n",
    "m_in1d.weight.data.normal_()\n",
    "m_in1d.bias.data.normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5367e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out1_in1d=m_in1d(inp_1d)\n",
    "out2_in1d=(inp_1d-inp_1d.mean(dim=(2,),keepdim=True))/torch.sqrt(inp_1d.var(dim=(2,),keepdim=True,unbiased=False)+m_in1d.eps)\n",
    "out2_in1d=out2_in1d*m_in1d.weight[None,:,None]+m_in1d.bias[None,:,None]\n",
    "print((out1_in1d-out2_in1d).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayerNorm applied to 2d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2d = torch.randn(20, 100, 35, 45)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 45])\n"
     ]
    }
   ],
   "source": [
    "m_ln2d=nn.LayerNorm(inp_2d.shape[2:])\n",
    "m_ln2d.weight.data.normal_()\n",
    "m_ln2d.bias.data.normal_()\n",
    "print(m_ln2d.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.5831e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out1_ln2d=m_ln2d(inp_2d)\n",
    "# Normalization step is like InstanceNorm2d\n",
    "out2_ln2d=(inp_2d-inp_2d.mean(dim=(2,3),keepdim=True))/torch.sqrt(inp_2d.var(dim=(2,3),keepdim=True,unbiased=False)+m_ln2d.eps)\n",
    "out2_ln2d=out2_ln2d*m_ln2d.weight[None,None,:,:]+m_ln2d.bias[None,None,:,:]\n",
    "print((out1_ln2d-out2_ln2d).abs().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayerNorm to 1d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1d=torch.randn(20,35,100)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "m_ln1d=nn.LayerNorm(inp_1d.shape[2:])\n",
    "m_ln1d.weight.data.normal_()\n",
    "m_ln1d.bias.data.normal_()\n",
    "print(m_ln1d.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9073e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out1_ln1d=m_ln1d(inp_1d)\n",
    "out2_ln1d=(inp_1d-inp_1d.mean(dim=(2,),keepdim=True))/torch.sqrt(inp_1d.var(dim=(2,),keepdim=True,unbiased=False)+m_ln1d.eps)\n",
    "out2_ln1d=out2_ln1d*m_ln1d.weight[None,None,:]+m_ln1d.bias[None,None,:]\n",
    "print((out2_ln1d-out1_ln1d).abs().max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
